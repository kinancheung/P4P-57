MobileNet models
0.043462614480175965
broadcasting
0.03226550159903557
Pixel phones
0.029670010025954773
generations
0.0288615463680004
XNNPACK
0.022209315760189963
Android
0.02220049036470395
ArXiv
0.021407982833544125
Linux
0.018930818541600492
floating-point neural network inference operators
0.016481565294197843
inputs
0.015586058927824855
Paper
0.015579140089756433
Publications

Marat Dukhan
0.01552808671540555
macOS
0.0129955104068717
integer
0.012963619305337895
1.0X
0.012885850349255618
WatchOS
0.012283716999703468
iOS
0.01222137128981478
ARM64
0.01170284731458582
channels
0.011212938918104254
PyTorch
0.01103774226868572
MediaPipe
0.011032136887790058
subset
0.010964883218474756
x86 platforms
0.01044463518564826
TensorFlow Lite
0.010411900000485844
randomized weights
0.010258517045840602
Raspberry Pi

The table
0.010128425530738078
input tensor
0.010090259661615177
operators
0.0100178200593034
ms
MobileNet v1
0.009735773309990781
single-threaded performance
0.009700715255526855
WebAssembly
0.009651298719834238
table
0.008983885947542682
low-level performance
0.008737370541044953
XNNPACK

XNNPACK
0.007570835296143415
QNNPACK library
0.007461599992413663
tvOS
0.00725849934832036
Architectures
0.007155876189616536
workshop
0.007110873718946108
slides, paper
0.006952629455692102
ARMv7
0.006943572713495523
TensorFlow.js
0.006901379962430508
NEON
0.006858538200212818
ReLU
0.006814266487409331
ReLU6
0.006743469154171634
ECV
0.006736623535736336
Trevor Gale
0.006704145120731331
Windows
0.006702334500484491
Minimum
0.006688873976036
Maximum
0.006685737896050623
Karen Simonyan
0.006642449858366463
Multiply
0.006619168815932811
Divide
0.006615819970329664
Erich Elsen
0.006489196910740576
Compute Vision
0.006389606212588085
pre-trained sparse
models
0.006352471518008197
Subtract
0.006314721351114987
Squared Difference
0.006287062791834287
Fast Sparse ConvNets
0.006280190452953692
Clamp
0.006275072952234806
Yury Pisarchyk
0.0061241134752479266
codebase
0.006052407574186203
AVX512
0.005998114970565734
AKA Pixel Shuffle
0.005990507157627854
Add
0.005930719250396337
time
0.0059167408754154435
Copy
ELU
Floor
0.005903696641811784
Abs
0.005889880874266078
Artsiom Ablavatski
0.005878510249545971
absolute value
0.005852514119450529
Efficient Deep Learning
0.005812824790166506
Global Average Pooling
Channel Shuffle
0.0057453565072620675
frameworks
0.005735895246990506
Space
0.005731783864776907
Juhyun Lee "Efficient Memory Management
0.005722063558503911
deep learning practitioners
0.005707202558389968
XNNPACK support NHWC layout
0.0056644989910538835
Ceiling
0.005663068854758611
Large
0.005643375903231263
ms RPi
0.005616915775585629
Zero W
0.005615348980447361
direct use
0.005606190384921286
BCM2835
0.005597864306315901
BCM2836
0.00558669460786671
Channel dimension
0.005585192887018213
Optimization
0.0055593309181507684
ARM
0.005552416122709009
Two-Pass Softmax Algorithm
0.005549599449703872
Samsung
0.005536156586011061
lot
0.0054507895816916785
researchers
0.005427690158753749
Web.
Alibaba HALO
0.005418339046806966
Indirect Convolution Algorithm
0.005406714333645039
custom stride
0.005395358127033425
simulator
WebAssembly MVP
WebAssembly SIMD
0.005270394023048601
ties
0.005265939370918432
Raspbian Buster
0.005258382859845156
big cores) performance
0.005256305971051338
end2end_bench --benchmark_min_time=5
0.005256102964431209
Heterogeneity-Aware Lowering
0.005212260354865484
CMake
0.005200137307021683
BCM2837B0
0.005158468141830632
device
0.005126527533105463
Deep Neural Net Inference
0.005113268991815711
Performance

Mobile phones
0.005101471985092553
end2end-bench --benchmark_min_time=5
0.005076845858986335
cost Channel Split and Channel Concatenation operations
0.005070707674169365
android_arm64 :end2end_bench
0.005070522436520788
March
0.0050262175358871605
HardSwish
Leaky ReLU
Negate
Sigmoid
Softmax
Square
Truncation
0.004991676515627629
many threads
0.004989938996828293
2D Convolution
0.004976433797358833
grouped and depthwise)
2D Deconvolution
0.004947801359524001
May
0.0048492721262254745
BCM2711
0.004842331811577762
AKA Transposed Convolution
0.004743296613661412
2D Average Pooling
2D Max Pooling
0.004565072828378203
optimized library
0.004563380613341305
