ms
FP32 MobileNet v1
0.04168036130416563
broadcasting
0.029421246436260467
Pixel phones
0.026221085251778183
generations
0.025771337995082747
v3
0.020580013486163326
Model RPi
0.019869258623910698
XNNPACK
0.019810927377848193
ArXiv
0.018874797496767286
Linux
0.017271128750463875
Android
0.015316641906528632
floating-point neural network inference operators
0.015161765478589828
1.0X
0.014343072116477767
inputs
0.01430807913426204
MobileNet models
0.01420005770037602
Paper
0.013750388502612527
Publications

Marat Dukhan
0.013391050622895351
macOS
0.01211301831675158
integer
0.011425901967306407
ARM64
0.010635513246862075
channels
0.009923806589131862
x86 platforms
0.009901527746577227
MediaPipe
0.009900700449505782
PyTorch
0.009868523533272357
subset
0.009708648178745446
WebAssembly
0.009622831973803782
TensorFlow.js
0.009495369091263545
Raspberry Pi

The table
0.009358554905517836
TensorFlow Lite
0.009316122869018544
randomized weights
0.00915991223536047
Large
0.009003116645866997
input tensor
0.008949518554188187
operators
0.008871624638412453
single-threaded performance
0.008660108516094599
BCM2711
0.008299466404339616
table
0.008137868420960724
low-level performance
0.00794860382510144
XNNPACK

XNNPACK
0.006790313738019033
WatchOS
0.006737662944829143
tvOS
0.006697923831265342
QNNPACK library
0.006633108874489255
Architectures
0.0065031083707778325
iOS
0.006497778782125198
Windows
0.0063013346003793335
ARMv7
0.006299735436319264
workshop
0.006287700781608272
ReLU6
0.00621267699150295
ReLU
0.006195999994389932
slides, paper
0.006150026611093597
Maximum
0.006072769036028132
Minimum
0.00605915479279455
Divide
0.006028997162836575
VFPv2
0.006024369028875977
Multiply
0.005981712825162724
NEON
0.00596807493762214
ECV
0.005958996464719763
Trevor Gale
0.005938886759389535
Karen Simonyan
0.005884310156726793
Zero W
0.005871454687383832
ARMv6
0.0058651816893588084
Subtract
0.005781970561424896
Convert
0.005777877514274698
Erich Elsen
0.005749164892264728
Squared Difference
0.0056715126112146285
BCM2835
0.005655393073299575
Compute Vision
0.0056526367967772075
AVX512
0.005647970957267675
Clamp
0.0056382062140618245
pre-trained sparse
models
0.005627702643453991
AKA Pixel Shuffle
0.005613079127931825
Fast Sparse ConvNets
0.005567377040864244
Add
0.005506316172714599
RV32GV
0.005449279480552491
Yury Pisarchyk
0.005430498082379821
Space
0.005416094726463629
RV64GC
0.0053740782079503965
codebase
0.005368511511434628
BCM2836
0.005346736612433562
INT8 inference
0.00530739397670221
fixed-point and half-precision quantization
0.005265282919570332
WebAssembly SIMD
RISC-V
0.00525175575618131
time
0.005250842698683065
Abs
0.00523741449890449
Artsiom Ablavatski
0.005219673053743982
frameworks
0.005204734097121141
absolute value
0.005179808991129502
Global Average Pooling
Channel Shuffle
0.0051690021295559
deep learning practitioners
0.005168846568444756
BCM2837B0
0.0051637627010412135
Efficient Deep Learning
0.005140808091543262
Juhyun Lee "Efficient Memory Management
0.005081143570769178
direct use
0.0050722511143736085
XNNPACK support NHWC layout
0.0050270547026899925
ARM
0.005000322000040507
Channel dimension
0.004970509620705637
Optimization
0.004944714321259087
Two-Pass Softmax Algorithm
0.004931230073129921
researchers
0.004925800805331672
Samsung
0.004924153368849573
dequantization
0.004894907838478287
Copy
ELU
Floor
0.004861435347970782
lot
0.0048372400004013435
Web.
Alibaba HALO
0.004825497039596007
custom stride
0.004802434442231601
2D Convolution
0.004793797295615966
Ceiling
0.0047922704159620525
end2end_bench --benchmark_min_time=5
0.004779609273243968
grouped and depthwise)
2D Deconvolution
0.0047456250082538
Indirect Convolution Algorithm
0.004743656421560497
indices
0.0047434814844201974
Max Pooling
0.004738148508241493
channel
0.004724022061635849
big cores) performance
0.004716089187164424
Heterogeneity-Aware Lowering
0.004641704391268376
March
0.004630190502765427
Raspbian Buster
0.004628781812741678
AKA Transposed Convolution
0.004584352197250424
android_arm64 :end2end_bench
0.004584042714186049
CMake
0.0045820920877858344
device
0.004565344554078088
Deep Neural Net Inference
0.004549815123503435
Performance

Mobile phones
0.0045435594228750206
cost Channel Split and Channel Concatenation operations
0.004524053780174118
many threads
0.004510807246550271
2D Average Pooling
2D Max Pooling
0.004496768526613691
end2end-bench --benchmark_min_time=5
0.004465005409463535
HardSwish
Leaky ReLU
Negate
Sigmoid
Softmax
Square
Transpose
Truncation
0.004366885409541978
Feb
0.004255662322635264
optimized library
0.004128580097294304
