ms
FP32 MobileNet v1
0.037687931941363204
broadcasting
0.029549761303704188
Pixel phones
0.026796398912778747
generations
0.026385321373769338
v3
0.021121221879789147
Android
0.020637457554665457
Model RPi
0.020453674605442257
XNNPACK
0.020217802620213006
ArXiv
0.019489804352266965
Linux
0.017516947621439773
floating-point neural network inference operators
0.015579141281980098
1.0X
0.014856001266635973
inputs
0.01456575018676793
MobileNet models
0.014555965862301077
Paper
0.014196961917149907
Publications

Marat Dukhan
0.013855795987014016
macOS
0.012128774815588939
integer
0.011872369875909632
WatchOS
0.011333801808861973
iOS
0.0112543310181505
XNNPACK

XNNPACK
0.010944606026836372
ARM64
0.010730261403487517
channels
0.010190560187127521
MediaPipe
0.010055255979680391
PyTorch
0.01002463445281748
subset
0.009971936348359646
TensorFlow.js
0.009650467006646781
WebAssembly
0.009631067892545265
Raspberry Pi

The table
0.009620959030289977
x86 platforms
0.009620445217009327
TensorFlow Lite
0.00948788270240749
randomized weights
0.009431468359759748
Large
0.009276830306515731
input tensor
0.009192141732885023
operators
0.009148902837758363
single-threaded performance
0.00889225463666785
BCM2711
0.008563248155590954
table
0.008351698216067585
low-level performance
0.008026128549279381
INT8 MobileNet v1
0.0072375604557999434
QNNPACK library
0.006808874160473146
tvOS
0.006690001396730448
Architectures
0.006552916494351305
workshop
0.006530628646570214
ARMv7
0.006415501935944656
slides, paper
0.006386454527009432
Windows
0.006346319005742935
NEON
0.00634238271772254
ReLU
0.006258010005026949
ReLU6
0.006194192779398554
ECV
0.006189650674882504
Trevor Gale
0.00616455830335735
Minimum
0.006149028928022281
Maximum
0.006148429616486114
Karen Simonyan
0.006108076166435416
Divide
0.006088209197470636
Multiply
0.006084731071868762
Zero W
0.006066709460453701
Erich Elsen
0.005967098706422581
Compute Vision
0.005871483678342936
BCM2835
0.00584545038664349
pre-trained sparse
models
0.005835772758483768
Subtract
0.005820432443746613
Squared Difference
0.005786169470290706
Fast Sparse ConvNets
0.005777929878590254
Clamp
0.005771560943835949
AVX512
0.005682160628517622
Yury Pisarchyk
0.0056276634711687375
AKA Pixel Shuffle
0.005550483358850203
codebase
0.005538639376029815
BCM2836
0.0055286296454138475
INT8 inference
0.0054992110231423304
Add
0.005486884945883376
simulator
WebAssembly MVP
0.005454793656834905
Copy
ELU
Floor
0.005437614934283061
Abs
0.00543363235615755
time
0.005414543058696753
Artsiom Ablavatski
0.005413677756116557
absolute value
0.005399770936771728
BCM2837B0
0.005341591619331204
Efficient Deep Learning
0.005339358871029425
Space
0.0053210864223581286
Global Average Pooling
Channel Shuffle
0.005300217872811038
frameworks
0.005278609378775933
Juhyun Lee "Efficient Memory Management
0.005265416769089969
deep learning practitioners
0.005249641065942367
Ceiling
0.005222249681854668
XNNPACK support NHWC layout
0.005205313367237247
direct use
0.0051524820395960555
Channel dimension
0.005133523724334882
Two-Pass Softmax Algorithm
0.00511385378765188
Optimization
0.005100098305641389
Samsung
0.005074552600898145
ARM
0.005067276219858925
researchers
0.0050018850294979685
lot
0.004990250775095595
Web.
Alibaba HALO
0.004971736302943237
custom stride
0.004965896848415067
Indirect Convolution Algorithm
0.004925900773574939
end2end_bench --benchmark_min_time=5
0.004913420084175468
channel
0.0049034972463412665
2D Convolution
0.004879960860922327
ties
0.004868233203891965
big cores) performance
0.004857124289651701
Raspbian Buster
0.004819784224219465
Heterogeneity-Aware Lowering
0.00478949830819775
grouped and depthwise)
2D Deconvolution
0.00477937921399432
March
0.004766908659101718
CMake
0.004765986336974679
android_arm64 :end2end_bench
0.0047163031840141215
Deep Neural Net Inference
0.004711311952694669
device
0.004685227814528326
Performance

Mobile phones
0.004682277123630702
cost Channel Split and Channel Concatenation operations
0.004663268043573749
end2end-bench --benchmark_min_time=5
0.004657359702318229
many threads
0.004647233794926044
HardSwish
Leaky ReLU
Negate
Sigmoid
Softmax
Square
Truncation
0.004612385863754596
AKA Transposed Convolution
0.0045227233578961044
Oct
0.0044479426033677966
2D Average Pooling
2D Max Pooling
0.004336938014341645
optimized library
0.004180490476051316
