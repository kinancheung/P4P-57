MobileNet models
0.05424269935502312
Pixel phones
0.0345103813084834
generations
0.033455413290958226
broadcasting
0.03282616978386696
XNNPACK
0.026794779640962857
1.0X
0.024956760466600364
Android
0.022628916992978528
Linux
0.022512933027944326
ArXiv
0.01880163334137249
inputs
0.017828548503857358
Publications

Marat Dukhan
0.017506986353385462
ms
MobileNet v1
0.016368902541507524
following neural network operators
0.015540242291681083
WatchOS
0.015024943998811106
iOS
0.014910374778946104
channels
0.013397661323307246
subset
0.013123271780431458
Paper
0.012403608197056555
input tensor
0.01202006297965383
QNNPACK library
0.011909253061592137
Raspberry Pi

The table
0.011754548487162059
randomized weights
0.011744860661398609
Large
0.011650956079501198
single-threaded performance
0.011255872073001157
low-level performance
0.010690798544181509
table
0.010620049765061835
floating-point neural network inference operators
0.009822552025831625
January
0.009780722296337826
XNNPACK

XNNPACK
0.009365843875627678
ARM64
0.009309908449458042
tvOS
0.008868384907809258
Architectures
0.008706721164596629
ARMv7
0.008480032626129421
NEON
0.008385105576667528
workshop
0.008210422758115106
TensorFlow Lite
0.008195960241261045
MediaPipe
0.008076404217305603
slides, paper
0.008017583175527513
Maximum
0.007932692894099633
Minimum
0.007894493240603461
Divide
0.007855107947718043
TensorFlow.js
0.007818883178349261
macOS
0.007767532989896341
ECV
0.007767495346996408
Multiply
0.0077044598348063285
Trevor Gale
0.007675446840140092
Karen Simonyan
0.007595602422382268
ReLU6
0.007529764367408064
WebAssembly
0.007461883653087578
Erich Elsen
0.007437349706953455
Subtract
0.007434660556020822
Compute Vision
0.0073580593167285845
WebAssembly MVP
WebAssembly SIMD
0.007240419817639872
pre-trained sparse
models
0.007203402935881453
ReLU
0.007195577502232034
Fast Sparse ConvNets
0.007152292105869018
x86 platforms
0.007127797617645284
indices
0.0071202372300867844
frameworks
0.007069551914152386
deep learning practitioners
0.007007869995889924
ARM
0.0069762388202361855
AVX512
0.006948868624274424
operators
0.006900340599837351
direct use
0.006890958909047458
Global Average Pooling
Channel Shuffle
Fully Connected
Clamp
0.006865452056991813
2D Unpooling
2D Bilinear Resize
Add
0.006748578733667366
HardSwish
Sigmoid
Softmax
PReLU

All operators
0.006719049678896652
Channel dimension
0.006708473444060949
simulator

Operator Coverage

XNNPACK implements
0.006688927624165128
Efficient Deep Learning
0.006675708704587651
researchers
0.006649645879568939
Max Pooling
0.006636724763866951
Artsiom Ablavatski
0.0065338300873732744
custom stride
0.006436292145895788
Model RPi
0.006398764512833213
experimental)
x86
0.006398005512898798
2D Convolution
0.00638654041340431
grouped and depthwise)
2D Deconvolution
0.006314754334603337
BCM2711
0.006235605370072481
Indirect Convolution Algorithm
0.006203486472163738
big cores) performance
0.006172857040241073
BCM2836
0.0061488633390913115
AKA Transposed Convolution
0.006109423364020211
Two-Pass Softmax Algorithm
0.006098721504428278
Raspbian Buster
0.006075685217939214
Performance

Mobile phones
0.006025467598928936
2D Average Pooling
2D Max Pooling
0.006018804437822161
cost Channel Split and Channel Concatenation operations
0.006009682246939169
CMake
0.0060018420981008905
XNNPACK support NHWC layout
0.005923148713428866
many threads
0.005878126143462555
end2end-bench --benchmark_min_time=5
0.0058554834165074204
BCM2837B0
0.005799620775895341
android_arm64 :end2end_bench
0.0056781423178952056
optimized library
0.005607854119285213
end2end_bench --benchmark_min_time=5
0.005498112334274526
API
0.004731067285312915
