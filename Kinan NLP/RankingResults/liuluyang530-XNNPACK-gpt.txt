MobileNet models
0.05383097743078819
Pixel phones
0.033766017316935244
generations
0.0326336362064644
broadcasting
0.03191258058871281
XNNPACK
0.03004362579911864
1.0X
0.024075044662390712
Android
0.021872642295204785
Linux
0.021767253786234373
ArXiv
0.0184926309384669
inputs
0.017384680591445763
Publications

Marat Dukhan
0.017231985848763058
Large
0.01616768563980726
following neural network operators
0.015139886193469811
WatchOS
0.01452791379527067
iOS
0.014412873576818998
MediaPipe
0.013264994345785886
channels
0.013036898120704873
subset
0.012770052831424905
Paper
0.01221578195361317
input tensor
0.011701120688827107
randomized weights
0.011465438297668168
Raspberry Pi

The table
0.011451893368736196
QNNPACK library
0.011370908823939168
ms
MobileNet v1
0.011153881825655996
single-threaded performance
0.010975189914858846
table
0.010356925613264829
low-level performance
0.01030626099986772
floating-point neural network inference operators
0.009479709965510806
ARM64
0.008978659491101503
XNNPACK

XNNPACK
0.008772677684547469
tvOS
0.008572796600074123
Web
0.008477879790000545
Architectures
0.008390587709596466
ARMv7
0.008200131724498471
.
PyTorch
0.008116810586104663
NEON
0.00811005575821092
workshop
0.008041028635038092
slides, paper
0.007857450696179104
TensorFlow Lite
0.00779212046820188
Maximum
0.007705582819561116
Minimum
0.007668988835194126
Divide
0.007630090236965559
ECV
0.007607158231826456
Trevor Gale
0.007540711338357085
macOS
0.007527000891843322
TensorFlow.js
0.007513210823860653
Multiply
0.007485269851155416
Karen Simonyan
0.007465995550790903
ReLU6
0.007317560506854491
Erich Elsen
0.007304994563178999
WebAssembly
0.007228310607970796
Subtract
0.007223055443440549
Compute Vision
0.007206090973602716
pre-trained sparse
models
0.007105502471958626
Fast Sparse ConvNets
0.007040407916938378
WebAssembly MVP
WebAssembly SIMD
0.00701109422543512
ReLU
0.006993555998096406
indices
0.006913432790070884
x86 platforms
0.006905319259815537
deep learning practitioners
0.006778821313588801
frameworks
0.006772133127131803
ARM
0.006759602680844577
AVX512
0.006734262011341496
operators
0.006712098429731589
Global Average Pooling
Channel Shuffle
Fully Connected
Clamp
0.006672619449553025
direct use
0.00666919995905923
2D Unpooling
2D Bilinear Resize
Add
0.006554129526049023
Efficient Deep Learning
0.0065391518757901505
HardSwish
Sigmoid
Softmax
PReLU

All operators
0.00653222350369225
Channel dimension
0.0065250533941112725
simulator

Operator Coverage

XNNPACK implements
0.006487205473929153
Artsiom Ablavatski
0.006452260644364514
Max Pooling
0.006444802705821365
researchers
0.006428621709367318
custom stride
0.006260584810493244
Model RPi
0.006210094763451127
experimental)
x86
0.006199848852903891
2D Convolution
0.006198953439666575
grouped and depthwise)
2D Deconvolution
0.006129523363640322
Indirect Convolution Algorithm
0.0060717180027319954
Two-Pass Softmax Algorithm
0.006024076362592197
big cores) performance
0.006021174309817815
BCM2836
0.005951390405373041
AKA Transposed Convolution
0.005931670497023916
Performance

Mobile phones
0.005869366782155334
Ecosystem

Machine Learning Frameworks

TensorFlow.js WebAssembly backend.
TensorFlow Lite
0.00586466720308622
cost Channel Split and Channel Concatenation operations
0.005852014639604653
2D Average Pooling
2D Max Pooling
0.00584462168727314
Raspbian Buster
0.005823176033754053
CMake
0.00579829425850794
XNNPACK support NHWC layout
0.0057621293446921944
many threads
0.005733408367872382
android_arm64 :end2end_bench
0.005551424623159817
BCM2837B0
0.005536761637669481
January
0.005506606744782182
BCM2711
0.005501318611464124
optimized library
0.005445331542478321
end2end_bench --benchmark_min_time=5
0.005418649075887861
end2end-bench --benchmark_min_time=5
0.005371020870696923
API
0.004547964064626131
